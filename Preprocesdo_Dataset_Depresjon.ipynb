{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1yx2oOLc7tZ2-lzF08URj_eGtnCfuu3cI",
      "authorship_tag": "ABX9TyPQvDni15XRo7ohMeyyPYMO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/miguelvelascop/PFG_Miguel_Velasco_Puig/blob/main/Preprocesdo_Dataset_Depresjon.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se importan librerías para manejar vectores y matrices (numpy) y manejar tablas (panda) más facilmente, y os, que permite moverse por el sistema de archivos más facilmente(en este caso por GoogleDrive)."
      ],
      "metadata": {
        "id": "UfsyFQK-9JwN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Ml_-kuc8l_N"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "También se importan las funciones de las librería de colab que permiten cargar archivos."
      ],
      "metadata": {
        "id": "gD8SMB1t9hYK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files, drive"
      ],
      "metadata": {
        "id": "wARezCwe9q2-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se van creando dataframes con cada csv cargado, se le aplican las funciones para obtener la media, desviación típica, el mínimo y el máximo, se pasan a arrays numpy para poder ir uniendolos y conseguir al final una matriz numpy con todos los datos necesarios, y las etiquetas añadidas. Se repite el proceso tanto con archivos de depresión como no depresión, y al final se concatenan ambas matrices."
      ],
      "metadata": {
        "id": "78YsZKFFB36s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame()\n",
        "#Se cargarn tres listas con todos los archivos csv del dataset (una para no depresión, otra para depresión y otro con datos sobre los voluntarios)\n",
        "ruta_Depresion='/content/drive/MyDrive/TFG/datasets/depresjon/condition'\n",
        "ruta_noDepresion='/content/drive/MyDrive/TFG/datasets/depresjon/control'\n",
        "ruta_Scores='/content/drive/MyDrive/TFG/datasets/depresjon/scores.csv'\n",
        "archivos_De = os.listdir(ruta_Depresion)\n",
        "archivos_noDe = os.listdir(ruta_noDepresion)\n",
        "scores=pd.read_csv(ruta_Scores,  sep=',',  comment='#')\n",
        "\n",
        "#Se declara una función para filtrar los datos incompletos posteriormente\n",
        "dayIsComplete = lambda x: x['activity'].count() == 1440\n",
        "\n",
        "#Agrupar todos los datos de depresión en un pandas\n",
        "#Prepocesado datos depresión\n",
        "\n",
        "cont=0;\n",
        "for i in archivos_De:\n",
        "  aux=pd.read_csv(ruta_Depresion+'/'+i,  sep=',',  comment='#')\n",
        "  aux['timestamp'] = pd.to_datetime(aux['timestamp'])\n",
        "\n",
        "  aux = aux.groupby('date').filter(dayIsComplete)\n",
        "\n",
        "  media = aux.groupby('date')['activity'].mean().to_numpy()\n",
        "  matriz=media\n",
        "\n",
        "  desv = aux.groupby('date')['activity'].std().to_numpy()\n",
        "  matriz = np.append([matriz],[desv],axis=0)\n",
        "\n",
        "  min = aux.groupby('date')['activity'].min().to_numpy()\n",
        "  matriz2 = min\n",
        "\n",
        "  max = aux.groupby('date')['activity'].max().to_numpy()\n",
        "  matriz2 = np.append([matriz2],[max],axis=0)\n",
        "\n",
        "  matriz = np.insert(matriz, matriz.shape[0], matriz2, 0)\n",
        "  total = aux.groupby('date')['activity'].sum().to_numpy()\n",
        "  matriz = np.append(matriz,[total],axis=0)\n",
        "\n",
        "  matriz=np.transpose(matriz)\n",
        "\n",
        "  #Añadir columna con genero\n",
        "  selected_score = scores[scores['number'] == i.split('.')[0]]\n",
        "  gender = selected_score['gender'].values[0]\n",
        "  n_filas = matriz.shape[0]\n",
        "  columna_genero = np.full((n_filas, 1), gender)\n",
        "  matriz = np.hstack((matriz, columna_genero))\n",
        "\n",
        "  if(cont==0):\n",
        "    matrizdefD=matriz\n",
        "  else:\n",
        "    matrizdefD=np.concatenate((matrizdefD, matriz))\n",
        "  cont=cont+1\n",
        "\n",
        "mediaAuxD = matrizdefD[:,4].mean()\n",
        "desED = matrizdefD[:,4].std()\n",
        "\n",
        "#Añadir fila de etiqueta (0, Depresión)\n",
        "a = np.zeros((1,matrizdefD.shape[0]))\n",
        "matrizdefD = np.insert(matrizdefD, 6, a, 1)\n",
        "\n",
        "print(\"Depession data size:\")\n",
        "print(matrizdefD.shape)\n",
        "\n",
        "#######################################\n",
        "#Prepocesado datos no depresión\n",
        "\n",
        "cont=0\n",
        "for i in archivos_noDe:\n",
        "  aux=pd.read_csv(ruta_noDepresion+'/'+i,  sep=',',  comment='#')\n",
        "  aux['timestamp'] = pd.to_datetime(aux['timestamp'])\n",
        "\n",
        "  aux = aux.groupby('date').filter(dayIsComplete)\n",
        "\n",
        "  media = aux.groupby('date')['activity'].mean().to_numpy()\n",
        "  matriz=media\n",
        "\n",
        "  desv = aux.groupby('date')['activity'].std().to_numpy()\n",
        "  matriz = np.append([matriz],[desv],axis=0)\n",
        "\n",
        "  min = aux.groupby('date')['activity'].min().to_numpy()\n",
        "  matriz2 = min\n",
        "\n",
        "  max = aux.groupby('date')['activity'].max().to_numpy()\n",
        "  matriz2 = np.append([matriz2],[max],axis=0)\n",
        "\n",
        "  matriz = np.insert(matriz, matriz.shape[0], matriz2, 0)\n",
        "  total = aux.groupby('date')['activity'].sum().to_numpy()\n",
        "  matriz = np.append(matriz,[total],axis=0)\n",
        "\n",
        "  matriz=np.transpose(matriz)\n",
        "\n",
        "  #Añadir columna con genero\n",
        "  selected_score = scores[scores['number'] == i.split('.')[0]]\n",
        "  gender = selected_score['gender'].values[0]\n",
        "  n_filas = matriz.shape[0]\n",
        "  columna_genero = np.full((n_filas, 1), gender)\n",
        "  matriz = np.hstack((matriz, columna_genero))\n",
        "\n",
        "\n",
        "  if(cont==0):\n",
        "    matrizdefND=matriz\n",
        "  else:\n",
        "    matrizdefND=np.concatenate((matrizdefND, matriz))\n",
        "  cont=cont+1\n",
        "\n",
        "mediaAuxND = matrizdefND[:,4].mean()\n",
        "desEND = matrizdefND[:,4].std()\n",
        "\n",
        "#Añadir fila de etiqueta (1, No Depresión)\n",
        "a = np.ones((1,matrizdefND.shape[0]))\n",
        "matrizdefND = np.insert(matrizdefND, 6, a, 1)\n",
        "\n",
        "print(\"No depession data size:\")\n",
        "print(matrizdefND.shape)\n",
        "#Concatenar matrizes de depresión y no depresión\n",
        "\n",
        "matrizDef=np.concatenate((matrizdefD, matrizdefND))\n",
        "\n",
        "print(\"Final data size:\")\n",
        "print(matrizDef.shape)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1QoROZ1A6n4",
        "outputId": "da18c5c3-40fe-480c-f83a-405388693d1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "237714.25905292478 154473.72459996314\n",
            "Depession data:\n",
            "[1.16794444e+02 2.33477859e+02 0.00000000e+00 1.77300000e+03\n",
            " 1.68184000e+05 2.00000000e+00 0.00000000e+00]\n",
            "Depession data size:\n",
            "(359, 7)\n",
            "270335.8805970149 219628.71432567041\n",
            "No depession data:\n",
            "[1.85568056e+02 3.46555786e+02 0.00000000e+00 3.09700000e+03\n",
            " 2.67218000e+05 2.00000000e+00 1.00000000e+00]\n",
            "No depession data size:\n",
            "(670, 7)\n",
            "Final data size:\n",
            "(1029, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora se pasa la matriz numpy con los datos obtenidos a un dataframe pandas"
      ],
      "metadata": {
        "id": "i06RR27z_9je"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataFrame= pd.DataFrame(matrizDef, columns = ['media','desviacion_tipica','minimo','maximo','total','genero','etiqueta'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "3wvGsjUvADFn",
        "outputId": "3a28643b-3232-4d95-e963-e427e258766f"
      },
      "execution_count": null,
      "outputs": [],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "dataFrame",
              "summary": "{\n  \"name\": \"dataFrame\",\n  \"rows\": 1029,\n  \"fields\": [\n    {\n      \"column\": \"media\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 138.91235085647614,\n        \"min\": 0.0,\n        \"max\": 626.2902777777778,\n        \"num_unique_values\": 947,\n        \"samples\": [\n          251.8798611111111,\n          6.385416666666667,\n          258.6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"desviacion_tipica\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 185.33057203943454,\n        \"min\": 0.0,\n        \"max\": 1080.894993400051,\n        \"num_unique_values\": 951,\n        \"samples\": [\n          130.06813838123358,\n          418.7351715999401,\n          461.1827529506932\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"minimo\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.112362487776735,\n        \"min\": 0.0,\n        \"max\": 7.0,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0.0,\n          5.0,\n          2.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"maximo\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1459.9355831215148,\n        \"min\": 0.0,\n        \"max\": 8000.0,\n        \"num_unique_values\": 346,\n        \"samples\": [\n          3280.0,\n          4354.0,\n          1782.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 200033.78523332567,\n        \"min\": 0.0,\n        \"max\": 901858.0,\n        \"num_unique_values\": 947,\n        \"samples\": [\n          362707.0,\n          9195.0,\n          372384.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"genero\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4962965932262723,\n        \"min\": 1.0,\n        \"max\": 2.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          2.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"etiqueta\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4768484561859757,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Por último, se importa el dataframe a un csv y se descarga"
      ],
      "metadata": {
        "id": "GKYO2ox5AqzD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Con index=False se quitan los índices\n",
        "dataFrame.to_csv('Dataset_Depresjon_procesado.csv', index=False)\n",
        "files.download('Dataset_Depresjon_procesado.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "17gRMCA0A5w1",
        "outputId": "8e91c1ad-913c-4184-cdfd-df93d2db84dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_19594e42-b104-40c7-a06c-a6831ae100b1\", \"Dataset_Depresjon_procesado.csv\", 62283)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}
