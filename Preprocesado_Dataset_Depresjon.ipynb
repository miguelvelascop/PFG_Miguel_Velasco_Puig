{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1yx2oOLc7tZ2-lzF08URj_eGtnCfuu3cI",
      "authorship_tag": "ABX9TyPuj1f/ktCh8BKQxaRNseAQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/miguelvelascop/PFG_Miguel_Velasco_Puig/blob/main/Preprocesado_Dataset_Depresjon.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se importan librerías para manejar vectores y matrices (numpy) y manejar tablas (panda) más facilmente, y os, que permite moverse por el sistema de archivos más facilmente(en este caso por GoogleDrive)."
      ],
      "metadata": {
        "id": "UfsyFQK-9JwN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Ml_-kuc8l_N"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "También se importan las funciones de las librería de colab que permiten cargar archivos."
      ],
      "metadata": {
        "id": "gD8SMB1t9hYK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files, drive"
      ],
      "metadata": {
        "id": "wARezCwe9q2-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se van creando dataframes con cada csv cargado, se le aplican las funciones para obtener la media, desviación típica, el mínimo y el máximo, se pasan a arrays numpy para poder ir uniendolos y conseguir al final una matriz numpy con todos los datos necesarios, y las etiquetas añadidas. Se repite el proceso tanto con archivos de depresión como no depresión, y al final se concatenan ambas matrices."
      ],
      "metadata": {
        "id": "78YsZKFFB36s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame()\n",
        "#Se cargarn tres listas con todos los archivos csv del dataset (una para no depresión, otra para depresión y otro con datos sobre los voluntarios)\n",
        "ruta_Depresion='/content/drive/MyDrive/TFG/datasets/depresjon/condition'\n",
        "ruta_noDepresion='/content/drive/MyDrive/TFG/datasets/depresjon/control'\n",
        "ruta_Scores='/content/drive/MyDrive/TFG/datasets/depresjon/scores.csv'\n",
        "archivos_De = os.listdir(ruta_Depresion)\n",
        "archivos_noDe = os.listdir(ruta_noDepresion)\n",
        "scores=pd.read_csv(ruta_Scores,  sep=',',  comment='#')\n",
        "\n",
        "#Se declara una función para filtrar los datos incompletos posteriormente\n",
        "dayIsComplete = lambda x: x['activity'].count() == 1440\n",
        "\n",
        "#Agrupar todos los datos de depresión en un pandas\n",
        "#Prepocesado datos depresión\n",
        "\n",
        "cont=0;\n",
        "for i in archivos_De:\n",
        "  aux=pd.read_csv(ruta_Depresion+'/'+i,  sep=',',  comment='#')\n",
        "  aux['timestamp'] = pd.to_datetime(aux['timestamp'])\n",
        "\n",
        "  aux = aux.groupby('date').filter(dayIsComplete)\n",
        "\n",
        "  media = aux.groupby('date')['activity'].mean().to_numpy()\n",
        "  matriz=media\n",
        "\n",
        "  desv = aux.groupby('date')['activity'].std().to_numpy()\n",
        "  matriz = np.append([matriz],[desv],axis=0)\n",
        "\n",
        "  min = aux.groupby('date')['activity'].min().to_numpy()\n",
        "  matriz2 = min\n",
        "\n",
        "  max = aux.groupby('date')['activity'].max().to_numpy()\n",
        "  matriz2 = np.append([matriz2],[max],axis=0)\n",
        "\n",
        "  matriz = np.insert(matriz, matriz.shape[0], matriz2, 0)\n",
        "  total = aux.groupby('date')['activity'].sum().to_numpy()\n",
        "  matriz = np.append(matriz,[total],axis=0)\n",
        "\n",
        "  matriz=np.transpose(matriz)\n",
        "\n",
        "  #Añadir columna con genero\n",
        "  selected_score = scores[scores['number'] == i.split('.')[0]]\n",
        "  gender = selected_score['gender'].values[0]\n",
        "  n_filas = matriz.shape[0]\n",
        "  columna_genero = np.full((n_filas, 1), gender)\n",
        "  matriz = np.hstack((matriz, columna_genero))\n",
        "\n",
        "  if(cont==0):\n",
        "    matrizdefD=matriz\n",
        "  else:\n",
        "    matrizdefD=np.concatenate((matrizdefD, matriz))\n",
        "  cont=cont+1\n",
        "\n",
        "mediaAuxD = matrizdefD[:,4].mean()\n",
        "desED = matrizdefD[:,4].std()\n",
        "\n",
        "#Añadir fila de etiqueta (0, Depresión)\n",
        "a = np.zeros((1,matrizdefD.shape[0]))\n",
        "matrizdefD = np.insert(matrizdefD, 6, a, 1)\n",
        "\n",
        "print(\"Depession data size:\")\n",
        "print(matrizdefD.shape)\n",
        "\n",
        "#######################################\n",
        "#Prepocesado datos no depresión\n",
        "\n",
        "cont=0\n",
        "for i in archivos_noDe:\n",
        "  aux=pd.read_csv(ruta_noDepresion+'/'+i,  sep=',',  comment='#')\n",
        "  aux['timestamp'] = pd.to_datetime(aux['timestamp'])\n",
        "\n",
        "  aux = aux.groupby('date').filter(dayIsComplete)\n",
        "\n",
        "  media = aux.groupby('date')['activity'].mean().to_numpy()\n",
        "  matriz=media\n",
        "\n",
        "  desv = aux.groupby('date')['activity'].std().to_numpy()\n",
        "  matriz = np.append([matriz],[desv],axis=0)\n",
        "\n",
        "  min = aux.groupby('date')['activity'].min().to_numpy()\n",
        "  matriz2 = min\n",
        "\n",
        "  max = aux.groupby('date')['activity'].max().to_numpy()\n",
        "  matriz2 = np.append([matriz2],[max],axis=0)\n",
        "\n",
        "  matriz = np.insert(matriz, matriz.shape[0], matriz2, 0)\n",
        "  total = aux.groupby('date')['activity'].sum().to_numpy()\n",
        "  matriz = np.append(matriz,[total],axis=0)\n",
        "\n",
        "  matriz=np.transpose(matriz)\n",
        "\n",
        "  #Añadir columna con genero\n",
        "  selected_score = scores[scores['number'] == i.split('.')[0]]\n",
        "  gender = selected_score['gender'].values[0]\n",
        "  n_filas = matriz.shape[0]\n",
        "  columna_genero = np.full((n_filas, 1), gender)\n",
        "  matriz = np.hstack((matriz, columna_genero))\n",
        "\n",
        "\n",
        "  if(cont==0):\n",
        "    matrizdefND=matriz\n",
        "  else:\n",
        "    matrizdefND=np.concatenate((matrizdefND, matriz))\n",
        "  cont=cont+1\n",
        "\n",
        "mediaAuxND = matrizdefND[:,4].mean()\n",
        "desEND = matrizdefND[:,4].std()\n",
        "\n",
        "#Añadir fila de etiqueta (0, Depresión)\n",
        "a = np.ones((1,matrizdefND.shape[0]))\n",
        "matrizdefND = np.insert(matrizdefND, 6, a, 1)\n",
        "\n",
        "print(\"No depession data size:\")\n",
        "print(matrizdefND.shape)\n",
        "#Concatenar matrizes de depresión y no depresión\n",
        "\n",
        "matrizDef=np.concatenate((matrizdefD, matrizdefND))\n",
        "\n",
        "print(\"Final data size:\")\n",
        "print(matrizDef.shape)\n",
        "\n"
      ],
      "metadata": {
        "id": "A1QoROZ1A6n4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora se pasa la matriz numpy con los datos obtenidos a un dataframe pandas"
      ],
      "metadata": {
        "id": "i06RR27z_9je"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataFrame= pd.DataFrame(matrizDef, columns = ['media','desviacion_tipica','minimo','maximo','total','genero','etiqueta'])"
      ],
      "metadata": {
        "id": "3wvGsjUvADFn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Por último, se importa el dataframe a un csv y se descarga"
      ],
      "metadata": {
        "id": "GKYO2ox5AqzD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Con index=False se quitan los índices\n",
        "dataFrame.to_csv('Dataset_Depresjon_procesado.csv', index=False)\n",
        "files.download('Dataset_Depresjon_procesado.csv')"
      ],
      "metadata": {
        "id": "17gRMCA0A5w1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}